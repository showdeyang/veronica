# -*- coding: utf-8 -*-
#This script trains a model that determines whether a sentence can answer a given question well.
import json
import numpy as np
import math
import re
import jieba
import random
import matplotlib.pyplot as plt 
#
#with open('./baidu_zhidao.json','r') as f:
#    data = json.loads(f.read())
#
#rawData = []
#for qa in data:
#    q = qa['q']
#    if 'ans' in qa.keys():
#        if len(qa['ans']) > 0:
#            ans = [item['a'].replace('展开全部','') for item in qa['ans']]
#    rawData.append([q,ans])
#    
def relevance(qc,ac):
    c = 0 
    for x in qc:
        if x in ac:
            c += 1
    if len(qc) == 0:
        return 0
    else:
        return c/len(qc)

def depth(qc,ac):
    c = 0 
    for x in ac:
        if x in qc:
            c += 1
    if len(ac) == 0:
        return 0
    else:
        return c/len(ac)
    
def relevance2(qc,ac):
    qc = [item for item in qc if len(item)>=2]
    ac = [item for item in ac if len(item)>=2]
    c = 0 
    for x in qc:
        if x in ac:
            c += 1
    if len(qc) == 0:
        return 0
    else:
        return c/len(qc)

def depth2(qc,ac):
    qc = [item for item in qc if len(item)>=2]
    ac = [item for item in ac if len(item)>=2]
    c = 0 
    for x in ac:
        if x in qc:
            c += 1
    if len(ac) == 0:
        return 0
    else:
        return c/len(ac)

def qInA(q,a):
    c = 0
    for char in q:
        if char in a:
            c += 1
    if len(q) == 0:
        return 0
    else:
        return c/len(q)
    
def aInQ(q,a):
    c = 0
    for char in a:
        if char in q:
            c += 1
    if len(a) == 0:
        return 0
    else:
        return c/len(a)

def score(qc,ac):
    return relevance(qc,ac)*depth(qc,ac)

def score2(qc,ac):
    return relevance2(qc,ac)*depth2(qc,ac)

def prepareX(pair, ID):
    #this only prepares a row of X for a (q,a)-pair.
    q,a = pair[0], pair[1]
    qc,ac = list(jieba.cut(q)), list(jieba.cut(a))
    row = [score(qc,ac), score2(qc,ac), relevance(qc,ac), depth(qc,ac), relevance2(qc,ac), depth2(qc,ac), qInA(q,a), aInQ(q,a), len(qc), len(ac),  ID]
    #
    return row

def goodPairs(rawData):
    results = []
    for qa in rawData:
        for i in range(len(qa[1])):
            pair = [qa[0], qa[1][i]] 
            results.append(pair)
    return results
    
def badPairs(rawData,n=len(rawData)):
    results = []
    for i in range(n):
        c = random.choices(rawData,k=2)
        data1,data2 = c[0],c[1]
        q,a = data1[0],random.choice(data2[1])
        pair = [q,a]
        results.append(pair)
        
    for qa in rawData:
        for i in range(len(qa[1])):
            q = qa[0]
            k = 4
            v = random.choice(range(1,k))
            a = qa[1][i]
            for j in range(v):
                if len(a) > 4:
                    a = a.replace(random.choice(a),'')
            pair = [q,a] 
            results.append(pair)
    
    return results

def relu(z):
    #this modifies z in-place, this is the fastest way of doing ReLu. 
    z[z<0] = 0
    
def sigmoid(z):
    z[z>= 30] = 30
    return 1/(1+np.exp(-z))
    
def mlp(x, y, h=[]):
    #example: h = [50,20,10] means this mlp has three hidden layers of node count 50, 20 and 10 respectively. Default: no hidden layer.
    def genLayer(a1,a2):
        #a1 = input array size, a2 = output array size
        w = np.random.uniform(-10000,10000, size=(a1, a2))
        b = np.random.uniform(-10000,10000,a2)
        return w,b
    params = []
    if len(h) == 0: 
        w,b = genLayer(x,y)
        params.append((w,b))
    else:
        a = x
        for hl in h:
            #print(hl)
            w,b = genLayer(a,hl)
            params.append((w,b))
            a = len(b)
        #finally, between last h and output
        w,b = genLayer(h[-1],y)
        params.append((w,b))
    return params

def feedForward(x, params, onehot=True):
    #x,y must be numpy arrays, params must be generated by mlp().
    a = x
    h = []
    i = 1
    for param in params:
        w,b = param
        mul = np.dot(a,w)
        #print(np.size(mul))
        a = np.add(mul,b)
        #relu(a)
        a = sigmoid(a)
        if i < len(params):
            h.append(a)
        i += 1
        #print(params.index(param))
    
    if onehot:
        a[a>30] = 30
        #a[a<-9999] = -99
        #print(a)
        #print(np.sum(np.exp(a)))
        #y = np.exp(a)/np.sum(np.exp(a))
        y = a/np.sum(a)
        
    else:
        y = a
    return y,h

def predict(q,a,params):
    x = np.array(prepareX([q,a],0)[:-1])
    y,h = feedForward(x,params,onehot=False)
    y = y.flatten()
    return y

def mutation(params, variation, rate=1, offsprings=100):
    os = [params]
    for i in range(offsprings):
        rparams = []
        for param in params:
            w,b = param
            rw = w + np.random.normal(0,variation,np.shape(w))
            rb = b + np.random.normal(0,variation,np.shape(b))
            rparam = rw,rb
            rparams.append(rparam)
        os.append(rparams)
    return os

def training(xs, ys, teX, teY, n=100000, decision=0.5):
    params = mlp(10,1, h=[20,20,20])
    maxAcc = 0
    iteration = 0
    for j in range(n):
        iteration += 1
        print('training iteration',iteration)
        dev = math.sqrt(100*math.fabs(10000*maxAcc))/(math.sqrt((j+1)) )
        #dev += np.random.lognormal(0,10*dev)
        offsprings = int(10 + np.random.lognormal(100/(dev+1)))
        if offsprings > 30:
            offsprings = 30
        print('acc',maxAcc)
        print('dev', dev)
        print('offsprings',offsprings)
        params_offsprings = mutation(params,dev, offsprings=offsprings)
        offsprings = range(len(params_offsprings))
        
        #losses = []
        accuracies = []
        for i in offsprings:
            #i = 0,1,2,3,..., no of offsprings-1
            params = params_offsprings[i]
            FPRS,TPRS = [0],[0]
            
            #for d in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:
            #for d in [0.1,  0.3, 0.5,0.7, 0.9]:
            for d in range(1):
                ypred,h = feedForward(xs,params,onehot=False)
                ypred = ypred.flatten()
#                ypred[ypred<d] = 0
#                ypred[ypred>=d] = 1
    #            print(np.shape(ypred))
    
                #loss = np.mean(np.abs(ypred-ys))
#                TP = 0
#                TN = 0
#                FP = 0
#                FN = 0
#                for i in range(len(ypred)):
#    #                TP += ys[i]*ypred[i]
#    #                FN += ys[i]*(1-ypred[i])
#    #                FN += (1-ys[i])*ypred[i]
#    #                FN += (1-ys[i])*(1-ypred[i])
#                    
#    #                
#                    if ys[i]==1 and ypred[i] == 1:
#                        
#                        TP += 1
#                    elif ys[i]==1 and ypred[i] == 0:
#                        FN += 1
#                    elif ys[i]==0 and ypred[i] == 1:
#                        FP += 1
#                    elif ys[i]==0 and ypred[i] == 0:
#                        TN += 1
#                    
#                
#                if TP + FN == 0:
#                    TPR = 1
#                else:
#                    TPR = TP/(TP+FN)
#                if FP + TN == 0:
#                    FPR = 1
#                else:
#                    FPR = FP/(FP+TN)
#                TPRS.append(TPR)
#                FPRS.append(FPR)
#            FPRS.append(1)
#            TPRS.append(1)
#            acc = 0
#            #print(len(TPRS))
#            #print(len(FPRS))
#            for i in range(len(TPRS)-1):
                #print(i,acc)
                
                #acc += (TPRS[i+1] + TPRS[i])*(FPRS[i+1]-FPRS[i])/2.0
                acc = 1/(np.mean(np.abs(ys - ypred))+1)
            #loss = np.sum(np.abs(ys - ypred))/len(ys)
            #p = 1 - (e/len(teY))
            #print(loss)
            accuracies.append(acc)
            #losses.append(loss)
#        minLoss = np.min(losses)
#        minInd = losses.index(minLoss)
        
        maxAcc = np.max(accuracies)
        maxInd = accuracies.index(maxAcc)
        #survival params
        FPRS,TPRS = [0],[0]
        params = params_offsprings[maxInd]
        #for d in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:
        for d in [0.1,  0.3, 0.5,0.7, 0.9]:
            ypred,h = feedForward(teX,params,onehot=False)
            ypred = ypred.flatten()
            ypred[ypred<d] = 0
            ypred[ypred>=d] = 1
#            print(np.shape(ypred))

            #loss = np.mean(np.abs(ypred-ys))
            TP = 0
            TN = 0
            FP = 0
            FN = 0
            for i in range(len(ypred)):
#                TP += ys[i]*ypred[i]
#                FN += ys[i]*(1-ypred[i])
#                FN += (1-ys[i])*ypred[i]
#                FN += (1-ys[i])*(1-ypred[i])
                
#                
                if teY[i]==1 and ypred[i] == 1:
                    
                    TP += 1
                elif teY[i]==1 and ypred[i] == 0:
                    FN += 1
                elif teY[i]==0 and ypred[i] == 1:
                    FP += 1
                elif teY[i]==0 and ypred[i] == 0:
                    TN += 1
                
            
            if TP + FN == 0:
                TPR = 1
            else:
                TPR = TP/(TP+FN)
            if FP + TN == 0:
                FPR = 1
            else:
                FPR = FP/(FP+TN)
            TPRS.append(TPR)
            FPRS.append(FPR)
        FPRS.append(1)
        TPRS.append(1)
        acc = 0
        #print(len(TPRS))
        #print(len(FPRS))
        for i in range(len(TPRS)-1):
            #print(i,acc)
            
            acc += (TPRS[i+1] + TPRS[i])*(FPRS[i+1]-FPRS[i])/2.0
        
        #print('loss',minLoss)
        
        print('training Acc', maxAcc)
        print('test Acc',acc)
#        print('test TPR', TPR)
#        print('test FPR', FPR)
        print('test datapoints', len(teX))
#        print('test predicted positive', np.sum(ypred))
        #print(len(answer))
        print('\n#################\n')
              
    return params
#
#
#
#test_ratio = 0.3
#train_ratio = 1 - test_ratio
#n = len(rawData) #the number of questions
#
#gP,bP = goodPairs(rawData), badPairs(rawData,3*len(rawData))
#random.shuffle(gP)
#random.shuffle(bP)
#
#gpi,bpi = int(len(gP)*train_ratio), int(len(bP)*train_ratio)
#test_set_good, test_set_bad = gP[gpi:], bP[bpi:]
#train_set_good, train_set_bad = gP[:gpi], bP[:bpi]
#
#train_dataset = []
#test_dataset = []
#
#for i in range(len(train_set_good)):
#    train_dataset.append( prepareX(train_set_good[i],i) + [train_set_good[i][0], train_set_good[i][1], 1] )
#for j in range(len(train_set_bad)):
#    i = len(train_set_good)
#    train_dataset.append( prepareX(train_set_bad[j],i+j) + [train_set_bad[j][0], train_set_bad[j][1], 0] )  
#    
#for i in range(len(test_set_good)):
#    test_dataset.append( prepareX(test_set_good[i],i) + [test_set_good[i][0], test_set_good[i][1], 1] )
#for j in range(len(test_set_bad)):
#    i = len(test_set_good)
#    test_dataset.append( prepareX(test_set_bad[j],i+j) + [test_set_bad[j][0], test_set_bad[j][1], 0] )  
#
random.shuffle(train_dataset)
random.shuffle(test_dataset)

trX = np.array([row[:10] for row in train_dataset])
trY = np.array([row[-1] for row in train_dataset])

teX = np.array([row[:10] for row in test_dataset])
teY = np.array([row[-1] for row in test_dataset])
########################################
##Plotting

# Create data

x1 = [row[0] for row in train_dataset if row[-1]==1]
#print(len(x))
y1 = [row[1] for row in train_dataset if row[-1]==1]

x2 = [row[0] for row in train_dataset if row[-1]==0]
#print(len(x))
y2 = [row[1] for row in train_dataset if row[-1]==0]



c1 = 'blue'
c2 = 'red'
# Plot
plt.scatter(x1, y1, c='green', alpha=0.01)
plt.scatter(x2, y2, c='black', alpha=0.01)
plt.title('Scatter plot')
plt.xlabel('relevance')
plt.ylabel('relevance2')

plt.show()

###############################
#Training
#'''

#params = training(trX[:1000],trY[:1000],teX,teY)

#######################
#Testing
'适合冬天的运动有哪些？',
'''冬季运动宜选择轻松平缓、活动量不大的项目，如滑雪、慢跑、徒步、自行车等户外运动，以及高温瑜伽、游泳、普拉提等室内项目。适当减少登山、球类运动，以防止运动量过大使免疫力降低，诱发感冒、肺炎等疾病。'''


q = '适合冬天的运动有哪些？'
a = '''适合冬天的运动'''
z = predict(q, a, params)
print('actual isAnswer', 0)
print('model predicted', z)
qc = list(jieba.cut(q))
ac = list(jieba.cut(a))
z = score2(qc,ac)

if z >0.015:
    print('score2 predicted','1')
else:
    print('score2 predicted','0')
print('score2',z)
print('-----')

q = '适合冬天的运动有哪些？'
a = '''于这个值的实例划归为正类，小于这个值则划到负类中。如果减小阈值，减到0.5，固然能识别出的正类，也就是提高了识别出的正例占所有正例的比例，'''


z = predict(q, a, params)
print('actual isAnswer', 0)
print('model predicted', z)
qc = list(jieba.cut(q))
ac = list(jieba.cut(a))
z = score2(qc,ac)

if z >0.015:
    print('score2 predicted','1')
else:
    print('score2 predicted','0')
print('score2',z)
print('-----')

q = '适合冬天的运动有哪些？'
a = '''冬季运动宜选择轻松平缓、活动量不大的项目，'''
print('actual isAnswer', 1)
z = predict(q, a, params)
print('model predicted', z)
qc = list(jieba.cut(q))
ac = list(jieba.cut(a))
z = score2(qc,ac)

if z >0.015:
    print('score2 predicted','1')
else:
    print('score2 predicted','0')
print('score2',z)
print('-----')
q = '中国历史上谁杀人最多'
a = '''应该是白起，共计杀人一百余万，这还是白起的一张不完全统计的杀人账单。据梁启超考证，整个战国期间共战死两百万人，白起就占二分之一。铁血人屠当之无愧。'''
print('actual isAnswer', 1)
z = predict(q, a, params)
print('model predicted', z)
qc = list(jieba.cut(q))
ac = list(jieba.cut(a))
z = score2(qc,ac)

if z >0.015:
    print('score2 predicted','1')
else:
    print('score2 predicted','0')
print('score2',z)
print('-----')
q = '适合冬天的运动有哪些？'
a = '''冬季运动宜选择轻松平缓、活动量不大的项目，如滑雪、慢跑、徒步、自行车等户外运动，以及高温瑜伽、游泳、普拉提等室内项目。适当减少登山、球类运动，以防止运动量过大使免疫力降低，诱发感冒、肺炎等疾病。'''
print('actual isAnswer', 1)
z = predict(q, a, params)
print('model predicted', z)
qc = list(jieba.cut(q))
ac = list(jieba.cut(a))
z = score2(qc,ac)

if z >0.015:
    print('score2 predicted','1')
else:
    print('score2 predicted','0')
print('score2',z)